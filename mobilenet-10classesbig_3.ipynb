{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7723672,"sourceType":"datasetVersion","datasetId":4512031},{"sourceId":7727469,"sourceType":"datasetVersion","datasetId":4514846},{"sourceId":7727575,"sourceType":"datasetVersion","datasetId":4514922},{"sourceId":7727597,"sourceType":"datasetVersion","datasetId":4514940},{"sourceId":7727975,"sourceType":"datasetVersion","datasetId":4515227}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, layers\nfrom keras.layers import Dense, InputLayer, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom keras.callbacks import EarlyStopping as ES\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-29T09:18:19.263602Z","iopub.execute_input":"2024-02-29T09:18:19.264405Z","iopub.status.idle":"2024-02-29T09:18:39.764188Z","shell.execute_reply.started":"2024-02-29T09:18:19.264374Z","shell.execute_reply":"2024-02-29T09:18:39.763223Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-29 09:18:24.447969: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-29 09:18:24.448083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-29 09:18:24.735918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dir = '/kaggle/input/splitted-10-classes-of-food-plates/food_data_splitted/food_data_splitted/train'\ntest_dir= '/kaggle/input/splitted-10-classes-of-food-plates/food_data_splitted/food_data_splitted/test'","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:18:57.850670Z","iopub.execute_input":"2024-02-29T09:18:57.851348Z","iopub.status.idle":"2024-02-29T09:18:57.855575Z","shell.execute_reply.started":"2024-02-29T09:18:57.851315Z","shell.execute_reply":"2024-02-29T09:18:57.854450Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(\n    rescale=1./255.,\n    validation_split=0.2,\n)\ntest_gen = ImageDataGenerator(rescale=1./255.)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:19:01.830665Z","iopub.execute_input":"2024-02-29T09:19:01.831058Z","iopub.status.idle":"2024-02-29T09:19:01.836236Z","shell.execute_reply.started":"2024-02-29T09:19:01.831029Z","shell.execute_reply":"2024-02-29T09:19:01.835280Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"batchSize = 32\nimageShape = (224, 224)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:19:04.846324Z","iopub.execute_input":"2024-02-29T09:19:04.847174Z","iopub.status.idle":"2024-02-29T09:19:04.851008Z","shell.execute_reply.started":"2024-02-29T09:19:04.847142Z","shell.execute_reply":"2024-02-29T09:19:04.850116Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_ds = train_gen.flow_from_directory(train_dir,target_size=imageShape,batch_size=batchSize, subset='training', class_mode='categorical')\nval_ds = train_gen.flow_from_directory(train_dir,target_size=imageShape,batch_size=batchSize, subset='validation', class_mode='categorical')\ntest_ds = test_gen.flow_from_directory(test_dir,target_size=imageShape,batch_size=batchSize, class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:19:06.846506Z","iopub.execute_input":"2024-02-29T09:19:06.847185Z","iopub.status.idle":"2024-02-29T09:19:07.530860Z","shell.execute_reply.started":"2024-02-29T09:19:06.847154Z","shell.execute_reply":"2024-02-29T09:19:07.529945Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 6400 images belonging to 10 classes.\nFound 1600 images belonging to 10 classes.\nFound 2000 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_model():\n    \n    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    \n    for layers in base_model.layers:\n        layers.trainable = False\n        \n    base_model_output = base_model.output\n    \n    x = Flatten()(base_model_output)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(10, activation='softmax')(x)\n    \n    model = Model(inputs=base_model.input, outputs=x)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:19:10.388895Z","iopub.execute_input":"2024-02-29T09:19:10.389280Z","iopub.status.idle":"2024-02-29T09:19:10.395644Z","shell.execute_reply.started":"2024-02-29T09:19:10.389248Z","shell.execute_reply":"2024-02-29T09:19:10.394751Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.compile(loss='categorical_crossentropy', # No need to OHE target\n              optimizer='adam',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:19:15.281519Z","iopub.execute_input":"2024-02-29T09:19:15.282306Z","iopub.status.idle":"2024-02-29T09:19:17.592130Z","shell.execute_reply.started":"2024-02-29T09:19:15.282276Z","shell.execute_reply":"2024-02-29T09:19:17.591088Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train_ds,\n                        validation_data=val_ds,\n                        epochs=50,\n                        steps_per_epoch=len(train_ds),\n                    validation_steps=len(val_ds),\n                    callbacks=[ES(monitor=\"val_loss\", patience =5)])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:19:24.258865Z","iopub.execute_input":"2024-02-29T09:19:24.259569Z","iopub.status.idle":"2024-02-29T09:22:08.501208Z","shell.execute_reply.started":"2024-02-29T09:19:24.259536Z","shell.execute_reply":"2024-02-29T09:22:08.500271Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/200\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.1328 - loss: 14.0100","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1709198381.700401     129 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1709198381.732465     129 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.5889 - loss: 6.9463","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1709198429.805903     129 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 295ms/step - accuracy: 0.5898 - loss: 6.9035 - val_accuracy: 0.7319 - val_loss: 0.8716\nEpoch 2/50\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 3/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 144ms/step - accuracy: 0.9238 - loss: 0.2304 - val_accuracy: 0.7550 - val_loss: 1.0658\nEpoch 4/50\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 5/50\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 143ms/step - accuracy: 0.9805 - loss: 0.0639 - val_accuracy: 0.7931 - val_loss: 0.9270\nEpoch 6/50\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 7/50\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 141ms/step - accuracy: 0.9966 - loss: 0.0145 - val_accuracy: 0.7944 - val_loss: 0.9293\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:23:17.854649Z","iopub.execute_input":"2024-02-29T09:23:17.855603Z","iopub.status.idle":"2024-02-29T09:23:37.363196Z","shell.execute_reply.started":"2024-02-29T09:23:17.855561Z","shell.execute_reply":"2024-02-29T09:23:37.362372Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 307ms/step - accuracy: 0.7915 - loss: 1.0403\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1709198617.341747     130 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[0.997878909111023, 0.7950000166893005]"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\nimg_path = '/kaggle/input/testtt/test.jpg'\nimg = image.load_img(img_path, target_size=imageShape)\n\n# Preprocess the image\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array /= 255.\n\n# Make predictions\npredictions = model.predict(img_array)\npredicted_class_index = np.argmax(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:18:20.771963Z","iopub.execute_input":"2024-02-29T11:18:20.772498Z","iopub.status.idle":"2024-02-29T11:18:20.874841Z","shell.execute_reply.started":"2024-02-29T11:18:20.772464Z","shell.execute_reply":"2024-02-29T11:18:20.873965Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions , predicted_class_index","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:18:34.501974Z","iopub.execute_input":"2024-02-29T11:18:34.502353Z","iopub.status.idle":"2024-02-29T11:18:34.509037Z","shell.execute_reply.started":"2024-02-29T11:18:34.502323Z","shell.execute_reply":"2024-02-29T11:18:34.507985Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(array([[3.9702441e-09, 4.9961471e-07, 6.0218497e-09, 9.9999654e-01,\n         3.0004912e-06, 2.5297939e-10, 5.4229146e-09, 5.9536035e-08,\n         2.9653927e-08, 2.3244038e-09]], dtype=float32),\n 3)"},"metadata":{}}]},{"cell_type":"code","source":"class_labels = ['fish_and_chips', 'french_toast', 'fried_calamari', 'garlic_bread',\n                'grilled_salmon', 'hamburger', 'ice_cream', 'lasagna', 'macaroni_and_cheese','macarons']\n\n# Map the predicted class index to the corresponding class label\npredicted_label = class_labels[predicted_class_index]\n\nprint(\"Predicted class label:\", predicted_label)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:18:40.434753Z","iopub.execute_input":"2024-02-29T11:18:40.435465Z","iopub.status.idle":"2024-02-29T11:18:40.440913Z","shell.execute_reply.started":"2024-02-29T11:18:40.435430Z","shell.execute_reply":"2024-02-29T11:18:40.439800Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Predicted class label: garlic_bread\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gTTS","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:39:25.187133Z","iopub.execute_input":"2024-02-29T10:39:25.188055Z","iopub.status.idle":"2024-02-29T10:39:40.793551Z","shell.execute_reply.started":"2024-02-29T10:39:25.188021Z","shell.execute_reply":"2024-02-29T10:39:40.792383Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Collecting gTTS\n  Downloading gTTS-2.5.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from gTTS) (2.31.0)\nRequirement already satisfied: click<8.2,>=7.1 in /opt/conda/lib/python3.10/site-packages (from gTTS) (8.1.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\nDownloading gTTS-2.5.1-py3-none-any.whl (29 kB)\nInstalling collected packages: gTTS\nSuccessfully installed gTTS-2.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from gtts import gTTS\nimport IPython.display as ipd\n\n# Define a function to convert text to audio and play it\ndef text_to_audio(text, output_file='prediction_audio.mp3'):\n    tts = gTTS(text=text, lang='en')\n    tts.save(output_file)\n    return output_file\n\n\n# Define a dictionary to map class indices to class labels\nclass_mapping = {\n    0: 'fish and chips',\n    1: 'french toast',\n    2: 'fried calamari',\n    3: 'garlic bread',\n    4: 'grilled salmon',\n    5: 'hamburger',\n    6: 'ice cream',\n    7: 'lasagna',\n    8: 'macaroni and cheese',\n    9: 'macarons'\n}\n\n# Predicted class index\npredicted_class_index = predicted_class_index  # Replace with the actual predicted class index\n\n# Get the predicted class label from the mapping\npredicted_label = class_mapping[predicted_class_index]\n\n# Convert the predicted class label to audio and play it\naudio_file = text_to_audio(predicted_label)\nipd.Audio(audio_file)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:18:44.498036Z","iopub.execute_input":"2024-02-29T11:18:44.498886Z","iopub.status.idle":"2024-02-29T11:18:44.693030Z","shell.execute_reply.started":"2024-02-29T11:18:44.498854Z","shell.execute_reply":"2024-02-29T11:18:44.692160Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.Audio object>","text/html":"\n                <audio  controls=\"controls\" >\n                    <source src=\"data:audio/mpeg;base64,//NExAAAAANIAUAAAP8tYsQF0Fm/7THXn7v/MSzOzxLs5AzyZ7wwcJBn8zOIFm//nI9Sv9t+Vd6Hmf/5762QyYXO/nKH3iRIcCoJ//n+OUkGhpooMWAOcuZBinZHM+x0//NExFMRueJEAZo4ABmBA4ERGxyJVCCJfNEzcdYzY5ZaJsnzEhhMGIuxlB3h8QXUkHNy+6ApcR+LMJw1AmhdIiZM6vOmb0kDhULRgaHv9taZo6Bobppm2y32oMgtzA3P//NExF8hkxqIAY+AARfSdEtHi4XDUjP/3QTWtt9lJs3SOrW3/2/X1WLh5NaeuhzxiTSjACqVz2qi2jYUTdbpBIyObM5FEAhFM37BIoQPTS+mYAwSzb5MUj2GjzczUIhW//NExCsZSdacAdlYAAMEKDAtJaI/qNY0426bFU+5tBUnmIIA6Dq7DjJ+7/7/4/4+fvqTjOZqviZ+KVkiD8J////ywaLB3dTVnMcLYwUEIwJDNK/B6ENbeh1naK4Edoat//NExBgX+eakAM4UmUUX8VkyqwYICFCanZkGnIlUdmXKygZMVlGV+Ab2OqkYy7/7tZfqkESSzigMjdSxUZErWI27tqqeY+e7bly5ajPzPMP0MIDbsP5lVHTA7dqD4sjs//NExAsU6YqoAMaOlBWrrY/EDNooxdppSQxwwPb3EF7DRCOVpwAFwM3b7uLMYjPY5ai36+5K+8pbGw0RY2EuYTCEJC3ObVvvzfn3UagnIvk5ZkFGLMWM5fYZWLrRd+O0//NExAoTYZaoAM5UlMZNUO8qMJKvtSvKIBIISvN+bcjVwNm0MjqR0yrIduafUgEezWrsE2O6/GUNyfoeY6jAGDHexr6r6ff28x7mkSv6vK6VtZY5IemWJObLoy+pgpYc//NExA8VMP6kANZecA62M2YUJ0htnoZGDDzNUUYo6VJYOzV/QVW4AEQOYQxkaQzgF0NOfKlLyXNzvuCcio9z9QvURzJzST0fGYif/8sqHazv663mP9nR1648Cy59hQaD//NExA0VcOKgANZwcMmvfUeWDN6p2ki42tEwnz0KSsnI2IBTZgDFG0sygKoAGZdtv7S5gqZL9t8LlMn0oO/fMFFYlGPjr/U4IQL///Hf9KVC3////62X77hLgIELXwJf//NExAoTuO6gAM6wcJpfZ6BIxyCvEAqOPGbLadyd1OwtTJ5VDUUC4RUPMY9E1PB152lkjOhGhXk5df2jLzJ8Xrb+y15LUv7z7Gj//fLn72fTLpbf7u4OrCiHvmMGAXIq//NExA4UyPacANawcEhmfpE5zVLweYZrR2H2BJaGOZZvQBgSsF61SQ+Skm5irQtgUmyzm6tx05zmOEBJjL2nP+tL6jlN/+Xe0UcwTyRd/tbA9VW9a528IRAm+1qmjINk//NExA0VMgagAM6EmDlZcqrbioVDHALpxUVuy3ZIJtKfPF9XRps/stKgSX/jlEXJln48qxnD9dxq2NVCgIDbKV/Ir6/1+vqlqqjrzNstGtl0HUI0obOtXY4OiTgnHTpN//NExAsSAbaUANZElEuKoQ+NgiC1flK2zJgHn5bnep3ZL8y7dPtnqcEKyrdmpdl//jVx//UpW+3/qX8mUtC//+3QzmCNEQ+2c5GGc+8l7FA0MYJH5CwJDEK2pj4upcQU//NExBYSAdKQANzElMyaFLhUZ9E4aDHgDiJEihOIlABxBYEzBNBE73ofX53+X6/n9AAzLkLXp9fUOzPoN0YfhH/QQSShhopC/VemfkAiBpFKbeKNrPUsFnJSEWdrGoSp//NExCEX8cqUAN4KlBIsC3+TjYwMYIaoUySblii697nPwyvZc/HfFDef5/nd1nmFlxMfb68TToIFnWgAWrEJ2TzPZE7vv+7dnNRiTa9/m7CM4ZShdjKiGQ5w3w8Oor9R//NExBQVOcKoANYOlOADerZf3JbMZ5r827uLYu3spLADXp6zlHH9t7t+IgYM6D/mDR/b1H38+yat7s+t+p5x6bjxp2Lut7LJwQ////oSuYa4+4VbLzSDlVrYB7H5Yz29//NExBIQQSqoAM5OcKWUXZx/e9Rq///uzzXKt0B8AED41XGRoRPuPFD+7NzhxXW482IsllflUSpip//pmpNTeIlQlUwF0mY8IAzIJN7MDVCxTiuQI3cZYiSKL+ktFkr+//NExCQRyRaIAM0McE1H9u6LSxYBROSo4jlb/OV3NROJB0XAX/+gtBVkft/////1VQuRLow4zYMAnNsG7XIS1QstWUYEAWufqmzqxm7S4/zHXeys5jdUezuGcoeB0RgI//NExC8RWLZQAVoQAFmIPCpkXOqYPF76bLUC610Spa4U+31KRy5PCKgSf6f0VyqF5ncWAcajdZuPxIj4BcAkASA3ppibCSjGBJgDHDnifgB02wTAXtE8PMniai1GENUF//NExDwfoyp8AY9oAL8ly4X7S8kWEnV76SKkkUkndNE6bmm+9OtSjpgcOnDJBFSBcHumUzT/9FSS1KsqhTsh2///3a6DO3ZTfrrSUfQY0SrCVskJDwrXgsJiALQSP6om//NExBAQ6MqQAclIAbIarSJENDohQuAUUilCGQ8TiIfEWvRePuaRkgYzO4PaveecyfTVvjaIlqnv0l/CDj6k+90M06T9OnETTes0TsREiRS2SqGpS24BZhEqoi8okhQ7//NExB8R+O50AHpMcLonJolY8kQnKqjZo7QUBkKiIGg6TBWVPcFVBV09ypXrPW///WGtZ3/WAlQWBPqzxOde1Bhe5Fqa1S1OZV8uV7XPz/QcgmIWiiipAmBDwoTlC5I0//NExCoSmHJIAVoQAH3rcSEC1ijlKeg3v1Rf3alNeqKOc+hZPZt7UnXW72ilNQ913EOrUgNFDd2gd1fkFL3r7j/GRUVOgsKFgKBORD9G2hweiALiS/rSzTzBLiIHAvF///NExDIdaxpYAZlAAecOeWoRkDwEHEeOY70+4mg+HISVIcf//LxFPLVBMlkZQuhv9/HNfN/8/zs8TE7toZH/8/3191FXMff8/DlUYIt2Mnsqc+A24AQRlIZFWlAQAmGW//NExA8VmU6cAZmIAHQ/HO8wewLRuGiyZFCcJ0OwMcGKFIMmJ/LzJAcQ1ysaOm510CkXSdLrsTC0jRTLQoed/Ny+5oqnSMkSrOTYhICsAP/3f//9deVZavkcdqF1H3Xo//NExAsRcMKUAdrAAH1TgJyXZaSAARzEWrkGiIQprLaSOopqRdCndkicG5hUkVUBQJ+3DCtize2IDUDuZb5KSzHXV///9/+t1+4AMhZ78I2CJCblhsoVtNMwBy0lI4a///NExBgR4L6gAM5wTLnYbL7wLYj6aZblOmKNgUsUKVzARfwoNGZaremu5lppap1qUwIAMAHL////Wm7+pbOF1jAqDLLcMDNDm1qRgZyiKvY0XkBQmXZNITAbarH004Y5//NExCMSUNqoAM6ecL91qbJ+Mgm3N8xwRJxKwkAtJvKE0y6Fxcj8LhFyFjpCSv//93/mFancY8RS7fUUCG0dpBg5PUJ6vsmvcszym8mypHkl2NeGJdfqULLrJzoahqTJ//NExCwSCPqwAMYecFF1PEtgxENVrIoFUrWtFoh1dFrWH8+hGaU7//UqO3FcCinA4oOwWDgEY0y3Tq4Jh5Uxgs71/B27P1W61dVX2y3IrY124rYMKION1CTB9Zs1qr5h//NExDYR4RawAI4ecKiZn0Y+v2CTXgROv/+U+z9BGteQFwY3bwgaVvOFrhO2ZlpnewdgeXRU1Xvyt/36zzhuW7bXZeE++5+Xl1xJDJuBfW6+0d9syzGwudhXQ6/IPk////NExEERYRq4AH4YcN33adqKv4AFZAbig3LwTDBFWY+h7L52JGFFNXtutu6+Pc6R9LeHHJzz5ltO1Chgqfa2ITrd82jX93f1Wt3noah8sKtWf8X/6WOX9VWp90dLO9Z4//NExE4RiRq0AH4YcJW2NOqx7lCtij8UEHZkHvbvkflm+yqd/WfoHujQ9JBk6VQFxKZNI3p12u2FOmNvage1jtLkrPRzQxq6v9a79wEAo9lQDz9pBlE9qWEROb6DMEC3//NExFoQ+Sq0AMYWcOs8/3Wj2eVHF5qpamW/yCs8aNrA7xEjHNbCvtMxfmR/9rfLuckPote+8MrTb+y7StuxNUFQMRVCdB53LwIDTkQsHg5EyB3s0NEGvqCnLXO6S+He//NExGkSGTqsAMZYcPrbcmarUHGiRAmFDTcZZ5Vcny6V1Wep+SvSEyzqqrv1i3Kqkn0IABdqFhz/YPGChT0NirZ3GsXqs6apLu3Irh8v5ndy/d0ovEFLaQJrSBAiUPp1//NExHMQmS6oAJPScC47wy+GzN755o12Ia3Lp/6Xf/+v///8UqKWwQIUq4fUwqXbUC6RusNBCQKYYZYL5CLLqZVkYS7MRXMz3RpyS8OJUpEosNx5DVqlu+f28X7fmtqX//NExIMR8TakAMYWcAVHzppf/yTX//+d///4tQNIUOJSBUjCA6YV2bgeKEC8YGSSiCDGJp2HAEvf2zZq0t6a3Eikm2f27z9mNgGAkzXLoW4s8RciGjR7/U9LJaRVMYfJ//NExI4SaTaUAMRWcBAFzQCunjCEiA35ImDGJIKpKYgAKrC6EDanqTT/S6mtY6q6eZHOVd2TmuDEmgqtrzQBvQcFWlvojEoua9DKkaKCMp///SpBYXkHbL9Dx3/SRira//NExJcQEMJwANYMTMUnGB1b2PGv0b2zUtAjBHPoMhhzVYA7AnIcEuuOp21QE5PAjAnH/r533vc0RQIwTyMN5f/8shRl16ZubqksvVq/nv6QZX9ZvAIYI7wSwJx1lt9///NExKkSGMJUAVoQAP/9wxuyK/yWbmI3n1qbJPL0/65///+/mu6+Lnzc+1M+mbp0fPsTXhZCfQ3EUlicLoYyiWQM1nLWF5hk49rOIn+tn1nazVmLB4ZM8agXexeHpp3c//NExLMhsypkAZhYAOujnM2yzKyGvwr7gCku/t0iautz8nbncrUSuElNUgJAnk2hOI9mtaXTNWVOE9Wvo/X5pgHCOExYNkL+gueUo9Vp6ctM2mnf3X/sncvMycta1rMT//NExH8hmuqEAYlgAC1BMtZeS7FVASFJZ56i75gZMcPjrK2ZU1svpf4nw6ohaXlUIKPStJpsbgDATD8eSL1eDaDkItYijsjaqUnikEE+WlNVJ7XrYxc81aaVqEjZWNiZ//NExEsfWxIAAcxYAcUXUrNj1q1N02W01zklnPpv1FOSX6a64qfiT13N7ISu0XcsmWvuLa2Jmour6vZ902EkigKcZXucbUWCro7HpvLg37lYPLifoL2YJufD3aaBtbZR//NExCAaqvH8AHrGuTQ4xZA1BwlWXZu66dL2y5LTVkUCIlFBQsWiy9oOYJ+8xPZ7oTy2z3AHdDR9nqHvPRayGd1P/szM/PsSZHIXUOkWumZ5+2WDLuw6tQiPkSKEpUnA//NExAgSgTYEAEmGcLlhoeLIzbqNLK+9ulTGoDh8ZTX3AAccJwzvl5oWX6xEyFySYHCrzZFg6IWwKG1mDXNIWdv5KmLobpI7D3fZyqRWBQQJYN1f3hAg4GUE9ZBg4OAg//NExBEQ4FnwAGCGJAqIngBC4PiBjhKAiBkHzgvF3i5uMOPc9S3wxUKixQRtLlA/EByUY3s//9F+sPlAu8x5dQzQrUwZUeRXM2bQn16yBS55wMkai1PVV/MsdhyWz3nJ//NExCAVqa3wAHmGlPRqAqXVX9SZV/jVddqsO6lD2atdqsasomNYBAY8Ih4KiKCu0OkrCWz/sEuJZIGnqDp0KniwlLIAwKgcIyBGgXKHE1JwnLAQOOR///ZZLPssln////NExBwQcZVIAEjElP/7GVFVFRUVFVFQpgYIGDQWFhYXFRX4s3///+LC7FioqLCwsLB+TEFNRTMuMTAwqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqTEFNRTMu//NExC0AAANIAAAAADEwMKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqTEFNRTMu//NExIAAAANIAAAAADEwMKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq//NExKwAAANIAAAAAKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq//NExKwAAANIAAAAAKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq\" type=\"audio/mpeg\" />\n                    Your browser does not support the audio element.\n                </audio>\n              "},"metadata":{}}]},{"cell_type":"code","source":"model.save('/kaggle/working/model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:28:52.825717Z","iopub.execute_input":"2024-02-29T11:28:52.826198Z","iopub.status.idle":"2024-02-29T11:28:54.120861Z","shell.execute_reply.started":"2024-02-29T11:28:52.826158Z","shell.execute_reply":"2024-02-29T11:28:54.119805Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}